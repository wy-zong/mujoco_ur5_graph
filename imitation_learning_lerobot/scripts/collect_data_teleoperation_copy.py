from typing import Type
from pathlib import Path
import argparse

from loop_rate_limiters import RateLimiter
import numpy as np
import h5py
import cv2

from imitation_learning_lerobot.envs import Env, EnvFactory
from imitation_learning_lerobot.teleoperation import HandlerFactory

# === NEW: MuJoCo helpers for dynamic welds ===
import mujoco


def get_mj_handles(env):
    """Return (model, data) no matter env stores them as _mj_* or not."""
    if hasattr(env, "_mj_model") and hasattr(env, "_mj_data"):
        return env._mj_model, env._mj_data
    if hasattr(env, "model") and hasattr(env, "data"):
        return env.model, env.data
    raise RuntimeError("Cannot find MuJoCo model/data in env. Expected env._mj_model/_mj_data or env.model/env.data")


def mj_name2id(model, obj_type, name):
    _id = mujoco.mj_name2id(model, obj_type, name)
    if _id == -1:
        raise KeyError(f"MuJoCo name not found: {name}")
    return _id


def init_grasp_ids(model):
    """Resolve all ids we need once."""
    ids = {}
    # equality welds
    ids["eq_left"] = mj_name2id(model, mujoco.mjtObj.mjOBJ_EQUALITY, "grasp_left")
    ids["eq_right"] = mj_name2id(model, mujoco.mjtObj.mjOBJ_EQUALITY, "grasp_right")
    # pad geoms
    ids["left_pad_geoms"] = {
        mj_name2id(model, mujoco.mjtObj.mjOBJ_GEOM, "left_pad1"),
        mj_name2id(model, mujoco.mjtObj.mjOBJ_GEOM, "left_pad2"),
    }
    ids["right_pad_geoms"] = {
        mj_name2id(model, mujoco.mjtObj.mjOBJ_GEOM, "right_pad1"),
        mj_name2id(model, mujoco.mjtObj.mjOBJ_GEOM, "right_pad2"),
    }
    # actuator
    ids["act_fingers"] = mj_name2id(model, mujoco.mjtObj.mjOBJ_ACTUATOR, "fingers_actuator")
    return ids


def pad_touches_cloth(model, data, pad_geom_ids):
    """Return True if any contact involves a pad geom and a cloth geom."""
    for i in range(data.ncon):
        c = data.contact[i]
        g1, g2 = c.geom1, c.geom2
        if g1 in pad_geom_ids or g2 in pad_geom_ids:
            # name check: any geom whose name包含"cloth" 視為布料（flexcomp 展開的命名慣例）
            name1 = mujoco.mj_id2name(model, mujoco.mjtObj.mjOBJ_GEOM, g1) or ""
            name2 = mujoco.mj_id2name(model, mujoco.mjtObj.mjOBJ_GEOM, g2) or ""
            if ("cloth" in name1) or ("cloth" in name2):
                return True
    return False


def update_grasp_welds(model, data, ids, close_ctrl_threshold=180.0):
    """
    If fingers are closed AND pad touches cloth -> enable weld(s).
    Else -> disable all grasp welds.
    """
    act_id = ids["act_fingers"]
    is_closed = (data.ctrl[act_id] > close_ctrl_threshold)

    left_touch = pad_touches_cloth(model, data, ids["left_pad_geoms"])
    right_touch = pad_touches_cloth(model, data, ids["right_pad_geoms"])

    if is_closed and (left_touch or right_touch):
        if left_touch:
            model.eq_active0[ids["eq_left"]] = 1
        if right_touch:
            model.eq_active0[ids["eq_right"]] = 1
    else:
        model.eq_active0[ids["eq_left"]] = 0
        model.eq_active0[ids["eq_right"]] = 0

    # apply changes immediately
    mujoco.mj_forward(model, data)
# === NEW END ===


def parse_args():
    parser = argparse.ArgumentParser()

    parser.add_argument(
        '--env.type',
        type=str,
        dest='env_type',
        required=True,
        help='env type'
    )

    parser.add_argument(
        '--handler.type',
        type=str,
        dest='handler_type',
        required=True,
        help='handler type'
    )

    return parser.parse_args()


def teleoperate(env_cls: Type[Env], handler_type):
    handler_cls = HandlerFactory.get_strategies(env_cls.name + "_" + handler_type)
    handler = handler_cls()
    handler.start()
    handler.print_info()

    env = env_cls(render_mode="human")
    observation, info = env.reset()

    # === NEW: prepare MuJoCo ids once ===
    model, data = get_mj_handles(env)
    grasp_ids = init_grasp_ids(model)
    # 可選：把焊接一開始保證關閉
    model.eq_active0[grasp_ids["eq_left"]] = 0
    model.eq_active0[grasp_ids["eq_right"]] = 0
    mujoco.mj_forward(model, data)
    # === NEW END ===

    for camera in env_cls.cameras:
        cv2.namedWindow(camera, cv2.WINDOW_GUI_NORMAL)

    data_dict = {
        '/observations/agent_pos': [],
        **{f'/observations/pixels/{camera}': [] for camera in env_cls.cameras},
        '/actions': []
    }

    rate_limiter = RateLimiter(frequency=env.control_hz)

    action = handler.action
    last_action = action.copy()
    while not handler.done:
        if not handler.sync:
            rate_limiter.sleep()
            continue

        last_action[:] = action
        action[:] = handler.action
        if np.max(np.abs(action - last_action)) > 1e-6:
            data_dict['/observations/agent_pos'].append(observation['agent_pos'])
            for camera in env_cls.cameras:
                data_dict[f'/observations/pixels/{camera}'].append(observation['pixels'][camera])
            data_dict['/actions'].append(action)
        else:
            action[:] = last_action

        observation, reward, terminated, truncated, info = env.step(action)

        # === CALL: toggle welds based on contact & gripper state ===
        update_grasp_welds(model, data, grasp_ids, close_ctrl_threshold=180.0)
        # === CALL END ===

        env.render()
        for camera in env.cameras:
            cv2.imshow(camera, cv2.cvtColor(observation["pixels"][camera], cv2.COLOR_RGB2BGR))
        cv2.waitKey(1)

        rate_limiter.sleep()

    cv2.destroyAllWindows()
    handler.close()
    env.close()

    return data_dict


def write_to_h5(env_cls: Type[Env], data_dict: dict):
    h5_dir = Path(__file__).parent.parent.parent / Path("outputs/datasets") / Path(env_cls.name + "_hdf5")
    h5_dir.mkdir(parents=True, exist_ok=True)

    index = len([f for f in h5_dir.iterdir() if f.is_file()])

    h5_path = h5_dir / Path(f"episode_{index:06d}.hdf5")

    with h5py.File(h5_path, 'w', ) as root:

        episode_length = len(data_dict['/actions'])

        obs = root.create_group('observations')

        obs.create_dataset('agent_pos', (episode_length, env_cls.state_dim), dtype='float32', compression='gzip')

        pixels = obs.create_group('pixels')
        for camera in env_cls.cameras:
            shape = (episode_length, env_cls.height, env_cls.width, 3)
            chunks = (1, env_cls.height, env_cls.width, 3)
            pixels.create_dataset(camera, shape=shape, dtype='uint8', chunks=chunks, compression='gzip')

        root.create_dataset('actions', (episode_length, env_cls.action_dim), dtype='float32', compression='gzip')

        for name, array in data_dict.items():
            root[name][...] = array


def main():
    args = parse_args()

    env_cls = EnvFactory.get_strategies(args.env_type)

    data_dict = teleoperate(env_cls, args.handler_type)

    write_to_h5(env_cls, data_dict)


if __name__ == '__main__':
    main()
